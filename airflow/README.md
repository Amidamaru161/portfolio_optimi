# Airflow для портфельной оптимизации

Этот каталог содержит настройки Airflow для автоматизации процессов обработки данных, анализа и оптимизации портфеля.

## Структура проекта

```
airflow/
├── dags/                      # Каталог для DAG-файлов
│   ├── data_processing_dag.py # DAG обработки исходных данных
│   ├── analysis_dag.py        # DAG анализа и расчета технических индикаторов
│   ├── portfolio_optimization_dag.py # DAG оптимизации портфеля
│   ├── moex_download_dag.py   # DAG загрузки данных с MOEX
│   └── workflow_dag.py        # DAG полного рабочего процесса
├── docker-compose.yaml        # Конфигурация Docker для запуска Airflow
└── README.md                  # Этот файл
```

## Подготовка к запуску

1. Убедитесь, что у вас установлен Docker и Docker Compose.

2. Создайте необходимые каталоги для работы Airflow:

```bash
mkdir -p ./logs ./plugins
```

3. Установите переменную окружения AIRFLOW_UID для корректной работы с правами доступа:

```bash
echo -e "AIRFLOW_UID=$(id -u)" > .env
```

## Запуск Airflow

1. Запустите Airflow с помощью Docker Compose:

```bash
docker-compose up -d
```

2. После запуска веб-интерфейс Airflow будет доступен по адресу: http://localhost:8080/
   - Логин: airflow
   - Пароль: airflow

## Рабочий процесс

Airflow выполняет следующие DAG (направленные ациклические графы задач):

1. **moex_data_download** - загружает данные с MOEX:
   - Проверяет соединение с MOEX API
   - Загружает исторические данные свечей для списка тикеров
   - Сохраняет данные в CSV-файлы

2. **stock_data_processing** - обрабатывает исходные данные акций:
   - Проверяет наличие входных данных
   - Преобразует данные в дневной формат
   - Объединяет и фильтрует данные
   - Сохраняет обработанные данные

3. **stock_data_analysis** - анализирует обработанные данные:
   - Ожидает завершения предыдущего DAG (stock_data_processing)
   - Рассчитывает базовые технические индикаторы
   - Рассчитывает дополнительные расширенные индикаторы

4. **portfolio_optimization** - оптимизирует портфель:
   - Ожидает завершения предыдущего DAG (stock_data_analysis)
   - Рассчитывает ковариационную и корреляционную матрицы
   - Генерирует и анализирует случайные портфели
   - Находит оптимальные портфели (максимальный коэффициент Шарпа и минимальная волатильность)
   - Сохраняет результаты оптимизации

5. **portfolio_complete_workflow** - объединяет все DAG в один полный рабочий процесс:
   - Последовательно запускает все вышеперечисленные DAG
   - Ожидает завершения каждого этапа
   - Генерирует финальный отчет о результатах обработки

## Запуск полного рабочего процесса

Для запуска полного процесса от загрузки данных до оптимизации портфеля, активируйте DAG `portfolio_complete_workflow` в веб-интерфейсе Airflow. Он автоматически запустит все необходимые DAG в правильной последовательности и дождется завершения каждого этапа.

## Результаты

Результаты работы сохраняются в следующих каталогах:

- `/opt/airflow/data/` - исходные данные свечей с MOEX
- `/opt/airflow/data_daily/` - данные в дневном формате
- `/opt/airflow/data_processed/` - обработанные данные
- `/opt/airflow/data_processed/indicators/` - технические индикаторы
- `/opt/airflow/data_processed/portfolio/` - результаты оптимизации портфеля
- `/opt/airflow/data_processed/reports/` - итоговые отчеты

## Остановка и удаление

Для остановки и удаления контейнеров Airflow выполните:

```bash
docker-compose down
```

Для удаления всех данных, включая базу данных:

```bash
docker-compose down --volumes
``` 